{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:20:22.777965Z",
     "start_time": "2020-05-01T10:20:22.769214Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q1.1 (20%) Download the Adult dataset. Clean up the dataset and create x_train, y_train, x_test, y_test for training feature, training value, test feature, test label. All of these variables should be numpy arrays. Provide summary statistics for your training and test datasets so that TA can verify the correctness of your procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 資料匯入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:53:40.003985Z",
     "start_time": "2020-05-01T08:53:39.873366Z"
    }
   },
   "outputs": [],
   "source": [
    "Column = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\n",
    "          \"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\", \"capital-gain\",\n",
    "          \"capital-loss\",\"hours-per-week\",\"native-country\", \"income\"]\n",
    "train = pd.read_csv(\"adult_data.csv\", index_col = False, names = Column)\n",
    "test = pd.read_csv(\"adult_test.csv\", index_col = False, names = Column)\n",
    "test = test.drop(test.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:53:41.919469Z",
     "start_time": "2020-05-01T08:53:41.682803Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "# 處理缺失值，並把index重設\n",
    "train = train[train[Column] != \" ?\"].dropna()\n",
    "train = train.reset_index(drop = True)\n",
    "\n",
    "test = test[test[Column] != \" ?\"].dropna()\n",
    "test = test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 此時還需要注意，待會我們會進行Nominal Variable轉換成Dummy作為Model Feature的步驟，而依照題目指示，我們只要出現超過10次的Variable，通過train.iloc[;, n].value_counts( ) for n in [1,3,5,6,7,8,9,13]可得知，需要Drop掉的Nominal Variables有：\n",
    "    * Occupation: Armed-Forces\n",
    "    * Native-Country: Holand-Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:54:33.485205Z",
     "start_time": "2020-05-01T08:54:33.460668Z"
    }
   },
   "outputs": [],
   "source": [
    "Armed_Forces_train = train[train[\"occupation\"] == \" Armed-Forces\"].index\n",
    "Holand_Netherlands_train = train[train[\"native-country\"] == \" Holand-Netherlands\"].index\n",
    "Armed_Forces_test = test[test[\"occupation\"] == \" Armed-Forces\"].index\n",
    "\n",
    "train.drop(Armed_Forces_train, inplace = True)\n",
    "train.drop(Holand_Netherlands_train, inplace = True)\n",
    "test.drop(Armed_Forces_test, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:54:34.798796Z",
     "start_time": "2020-05-01T08:54:34.785953Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把test set的數值定為integer，與training set一致\n",
    "test[\"age\"] = test[\"age\"].astype(int)\n",
    "test[\"fnlwgt\"] = test[\"fnlwgt\"].astype(int)\n",
    "test[\"education-num\"] = test[\"education-num\"].astype(int)\n",
    "test[\"capital-gain\"] = test[\"capital-gain\"].astype(int)\n",
    "test[\"capital-loss\"] = test[\"capital-loss\"].astype(int)\n",
    "test[\"hours-per-week\"] = test[\"hours-per-week\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:54:35.666256Z",
     "start_time": "2020-05-01T08:54:35.602051Z"
    }
   },
   "outputs": [],
   "source": [
    "# 名目資料轉DUMMIES\n",
    "train = pd.get_dummies(train, columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\", \"income\"], drop_first = True)\n",
    "test = pd.get_dummies(test, columns = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\", \"income\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature-Label Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:55:35.287006Z",
     "start_time": "2020-05-01T08:55:35.254417Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, :94].values\n",
    "y_train = train.iloc[:, 94].values\n",
    "x_test = test.iloc[:, :94].values\n",
    "y_test = test.iloc[:, 94].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:06.837730Z",
     "start_time": "2020-05-01T10:25:06.830029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    39,  77516,     13, ...,      1,      0,      0],\n",
       "       [    50,  83311,     13, ...,      1,      0,      0],\n",
       "       [    38, 215646,      9, ...,      1,      0,      0],\n",
       "       ...,\n",
       "       [    58, 151910,      9, ...,      1,      0,      0],\n",
       "       [    22, 201490,      9, ...,      1,      0,      0],\n",
       "       [    52, 287927,      9, ...,      1,      0,      0]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:09.320353Z",
     "start_time": "2020-05-01T10:25:09.313138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:09.773349Z",
     "start_time": "2020-05-01T10:25:09.762902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    25, 226802,      7, ...,      1,      0,      0],\n",
       "       [    38,  89814,      9, ...,      1,      0,      0],\n",
       "       [    28, 336951,     12, ...,      1,      0,      0],\n",
       "       ...,\n",
       "       [    38, 374983,     13, ...,      1,      0,      0],\n",
       "       [    44,  83891,     13, ...,      1,      0,      0],\n",
       "       [    35, 182148,     13, ...,      1,      0,      0]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:11.543930Z",
     "start_time": "2020-05-01T10:25:11.536827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Summary statistics of features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:55:55.607331Z",
     "start_time": "2020-05-01T08:55:55.467157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Age</th>\n",
       "      <th>FnlWgt</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Capital-Gain</th>\n",
       "      <th>Capital-Loss</th>\n",
       "      <th>Hours-Per-Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>30152</td>\n",
       "      <td>38.440568</td>\n",
       "      <td>189791.552932</td>\n",
       "      <td>10.121319</td>\n",
       "      <td>1092.370025</td>\n",
       "      <td>88.266085</td>\n",
       "      <td>40.931348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>15055</td>\n",
       "      <td>38.769711</td>\n",
       "      <td>189604.611956</td>\n",
       "      <td>10.112255</td>\n",
       "      <td>1120.188907</td>\n",
       "      <td>89.071471</td>\n",
       "      <td>40.950714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count        Age         FnlWgt  Education-Num  Capital-Gain  \\\n",
       "Training  30152  38.440568  189791.552932      10.121319   1092.370025   \n",
       "Testing   15055  38.769711  189604.611956      10.112255   1120.188907   \n",
       "\n",
       "          Capital-Loss  Hours-Per-Week  \n",
       "Training     88.266085       40.931348  \n",
       "Testing      89.071471       40.950714  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEAN OF CONTINUOUS VARIABLES\n",
    "train_describe = [len(train)]\n",
    "for i in range(6):\n",
    "    sum_train= 0\n",
    "    for j in range(len(train)):\n",
    "        sum_train += x_train[j][i]\n",
    "    train_describe.append(sum_train/len(x_train))\n",
    "    \n",
    "test_describe = [len(test)]\n",
    "for i in range(6):\n",
    "    sum_test = 0\n",
    "    for j in range(len(test)):\n",
    "        sum_test += x_test[j][i]\n",
    "    test_describe.append(sum_test/len(x_test))\n",
    "    \n",
    "pd.DataFrame([train_describe, test_describe], index = [\"Training\", \"Testing\"], columns = [\"Count\", 'Age', 'FnlWgt', 'Education-Num', 'Capital-Gain', 'Capital-Loss',\n",
    "       'Hours-Per-Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T08:55:56.803107Z",
     "start_time": "2020-05-01T08:55:56.782366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;= 50k</th>\n",
       "      <th>&gt; 50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>22645</td>\n",
       "      <td>7507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>11358</td>\n",
       "      <td>3697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          <= 50k  > 50k\n",
       "Training   22645   7507\n",
       "Testing    11358   3697"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Counts\n",
    "from collections import Counter\n",
    "train_count = Counter(y_train)\n",
    "test_count = Counter(y_test)\n",
    "pd.DataFrame(data = [train_count.values(), test_count.values()], index = [\"Training\", \"Testing\"], columns = [\"<= 50k\", \"> 50k\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Q1.2 (20%) Derive the gradient and hessian matrix for the new E(w)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lambda Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:38:38.480738Z",
     "start_time": "2020-05-01T10:38:38.475040Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_vec1 = np.ones(x_train.shape[1] + 1)\n",
    "lambda_vec2 = np.hstack((np.ones(x_train.shape[1]), 0))\n",
    "lambda_vec3 = np.hstack((np.ones(5), np.array([0.5] * 89), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 初始Feature Weight，使用公式𝑤 = (𝑋<sup>𝑇</sup>𝑋+𝑏𝐼)<sup>−1</sup>𝑋<sup>𝑇</sup>𝑡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:32.104587Z",
     "start_time": "2020-05-01T10:25:31.895723Z"
    }
   },
   "outputs": [],
   "source": [
    "w = np.dot(np.linalg.inv(np.dot(x_train.T, x_train) + lambda_vec1.mean() * np.eye(x_train.shape[1])), np.dot(x_train.T, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:35.159389Z",
     "start_time": "2020-05-01T10:25:35.152271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.76285968e-03,  7.95062972e-08, -2.75693956e-03,  7.70476784e-06,\n",
       "        9.11983024e-05,  2.83119772e-03, -1.04182437e-01, -7.21730205e-02,\n",
       "       -1.66026332e-02, -1.38927468e-01, -1.18296027e-01, -2.17496320e-01,\n",
       "        2.84319210e-02,  5.37060012e-02, -5.37704550e-02, -4.56289945e-02,\n",
       "       -8.42049396e-02, -4.27561383e-02,  1.16528858e-01,  1.12520549e-01,\n",
       "        2.17335354e-01,  4.19439167e-01,  4.45101182e-02,  3.07537415e-01,\n",
       "       -3.62323913e-02,  3.76434042e-01,  9.31072233e-02,  1.89943178e-01,\n",
       "        9.93077142e-02,  3.05254783e-02, -9.91639598e-03,  1.21189483e-02,\n",
       "        1.62700799e-02, -2.17451430e-02,  1.25628263e-01, -1.08005070e-01,\n",
       "       -5.88570979e-02, -5.03328174e-02, -2.40657697e-02,  1.34223469e-02,\n",
       "        6.27060244e-02,  7.05143173e-02,  3.91081086e-02,  6.80940383e-02,\n",
       "       -4.47886986e-02, -1.78708546e-01, -1.47180592e-01, -1.53660589e-01,\n",
       "       -1.64257747e-01,  1.23375969e-01,  4.06891022e-02,  2.09184028e-02,\n",
       "       -6.77090778e-03,  3.63551004e-02,  6.52688261e-02, -4.21287042e-02,\n",
       "       -1.65050893e-01, -1.69715938e-01, -6.64168693e-02, -1.11625860e-01,\n",
       "       -8.34099027e-02, -7.22372144e-02, -3.35607890e-02,  3.85953869e-03,\n",
       "       -2.50727631e-02, -1.68191128e-01, -4.53475264e-02, -8.67236580e-02,\n",
       "       -7.57022072e-02, -9.40275840e-02, -9.58751916e-02, -1.31670127e-01,\n",
       "       -6.70602514e-02, -1.43893284e-02, -2.11943920e-03, -7.17509683e-02,\n",
       "       -2.92241428e-02, -1.53415787e-01, -1.12485253e-01, -1.31310844e-01,\n",
       "       -2.09487257e-01, -1.30731744e-01, -4.98784930e-02, -1.12423727e-01,\n",
       "       -1.01412243e-01, -9.68140350e-02, -1.41115611e-01, -1.93368644e-01,\n",
       "       -1.38941044e-01, -1.38101426e-01, -1.18566718e-01, -5.79839785e-02,\n",
       "       -1.50766083e-01, -1.18880481e-02])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 用Sigmoid Function得出給定X-Feature為C1_Class的機率為何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:25:52.193642Z",
     "start_time": "2020-05-01T10:25:52.189169Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(alpha):\n",
    "    return 1 / (1 + np.exp(-alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient\n",
    "    -  ∇E(ω) = Φ<sup>T</sup> · (y-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T12:02:02.986215Z",
     "start_time": "2020-05-01T12:02:02.960498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.29876918e+05, -1.79311471e+09, -8.66428459e+04,  6.47336680e+06,\n",
       "       -2.27054366e+05, -3.57480112e+05, -5.73333200e+02, -7.45744231e+03,\n",
       "       -8.02030576e+01, -7.09634854e+02, -3.79344231e+02, -7.05449477e+00,\n",
       "       -4.79525881e+02, -1.66134806e+02, -7.09982384e+01, -1.34977894e+02,\n",
       "       -2.52202356e+02, -2.08691182e+02, -3.10914359e+02, -3.94149543e+02,\n",
       "       -9.12594928e+02,  2.65221933e+01, -3.69982539e+03, -1.16621060e+02,\n",
       "       -2.25067504e+01,  4.00253609e+01, -2.32997432e+03, -2.89541799e+00,\n",
       "       -2.18841601e+03, -1.61627473e+02, -4.50558986e+03, -4.19789176e+02,\n",
       "       -3.53322924e+02, -1.33130914e+03, -5.27158645e+02, -4.07961954e+02,\n",
       "       -6.12503614e+02, -7.98133485e+02, -1.50639536e+03, -7.07339496e+01,\n",
       "       -6.44551233e+02, -1.63586457e+02, -1.05895397e+03, -2.46175075e+02,\n",
       "       -5.45906762e+02, -3.24142680e+03, -4.16690207e+02, -2.18431057e+03,\n",
       "       -1.44574273e+03, -1.77673131e+02, -2.59767862e+02, -1.13179728e+03,\n",
       "       -9.95575588e+01, -7.79045222e+03, -5.34782443e+03, -2.62520317e+01,\n",
       "       -1.89144801e+01, -2.65238197e+01, -2.71274448e+01, -3.20116640e+01,\n",
       "       -1.05004638e+01, -4.32023610e+01, -2.03128859e+01, -4.40544119e+00,\n",
       "       -3.07079036e+01, -8.48571763e+00, -2.92486829e+01, -1.80001033e+01,\n",
       "       -5.25059735e+00, -4.97744087e+00, -4.26617169e+00, -1.96339909e+01,\n",
       "       -7.38019831e+00, -8.23144495e+00, -1.58777178e+01, -3.24678335e+01,\n",
       "       -1.20411219e+01, -7.03224131e+00, -2.80131807e+02, -1.50248034e+01,\n",
       "       -7.05165192e+00, -1.35225645e+01, -4.86163266e+01, -1.97406499e+01,\n",
       "       -1.40113329e+01, -4.54699899e+01, -4.02850336e+00, -2.49641035e+01,\n",
       "       -6.59469890e+00, -6.26728671e+00, -7.52271758e+00, -8.45812658e+03,\n",
       "       -2.82585786e+01, -3.47059955e+00])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Gradient(x, y, w):\n",
    "    alpha = np.dot(x, w)\n",
    "    t = sigmoid(alpha)\n",
    "    return np.dot(x.T, (y-t))\n",
    "\n",
    "gradient = Gradient(x_train, y_train, w)\n",
    "gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hessian\n",
    "    - ∇E(ω) = Φ<sup>T</sup> · R · Φ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T10:26:04.679626Z",
     "start_time": "2020-05-01T10:25:56.382971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.19604528e+07, 5.23008304e+10, 2.82216517e+06, ...,\n",
       "        2.55288566e+05, 5.25079104e+02, 1.48045027e+02],\n",
       "       [5.23008304e+10, 3.45056407e+14, 1.38714402e+10, ...,\n",
       "        1.24594057e+09, 2.60837022e+06, 8.20864146e+05],\n",
       "       [2.82216517e+06, 1.38714402e+10, 7.86904187e+05, ...,\n",
       "        6.77254585e+04, 1.49773881e+02, 3.77258001e+01],\n",
       "       ...,\n",
       "       [2.55288566e+05, 1.24594057e+09, 6.77254585e+04, ...,\n",
       "        6.66116297e+03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.25079104e+02, 2.60837022e+06, 1.49773881e+02, ...,\n",
       "        0.00000000e+00, 1.57839717e+01, 0.00000000e+00],\n",
       "       [1.48045027e+02, 8.20864146e+05, 3.77258001e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.82039347e+00]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Hessian(x, w):\n",
    "    t = sigmoid(np.dot(x, w))\n",
    "    R = np.diag(t * (1 - t))\n",
    "    return np.dot(np.dot(x.T, R), x)\n",
    "    \n",
    "hessian = Hessian(x_train, w)\n",
    "hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1.3 (30%) Create your mylogistic_l2 class. Show the learned 𝑤 as well as test accuracy for the cases below. If 𝑤 is too long for you, show selected 𝑤 for continuous-valued, binary-valued, and the constant term.\\\n",
    "Case 1: lambda = 1 for all coefficients \\\n",
    "Case 2: lambda = 1 for all but the intercept, no regularization for intercept term. \\\n",
    "Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mylogistic_l2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:06:57.410353Z",
     "start_time": "2020-05-01T13:06:57.355464Z"
    }
   },
   "outputs": [],
   "source": [
    "class mylogistic_l2:\n",
    "    \n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec \n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "    def Sigmoid(self, alpha):  # 計算Sigmoid value，(P(Y|X))\n",
    "            return 1 / (1 + np.exp(-alpha))\n",
    "        \n",
    "    def fit(self, x, y):  # 找出最佳feature weighting\n",
    "        if self.add_intercept == True:  # 處理intercept\n",
    "            self.x = np.hstack((x, np.ones((x.shape[0], 1))))\n",
    "        self.y = y    \n",
    "     \n",
    "        # 1. 初始feature weighting\n",
    "        w = np.dot(np.linalg.inv(np.dot(self.x.T, self.x) + self.reg_vec.mean() * np.eye(self.x.shape[1])), np.dot(self.x.T, self.y))\n",
    "\n",
    "        # 2. gradient和hessian\n",
    "        def Gradient(x, y, w, lmda):\n",
    "            t = self.Sigmoid(np.dot(x, w))\n",
    "            return np.dot(x.T, (t - y)) + np.dot(lmda, w)\n",
    "        \n",
    "        def Hessian(x, w, lmda):\n",
    "            t = self.Sigmoid(np.dot(x, w))\n",
    "            R = np.diag(t * (1 - t))\n",
    "            return np.dot(np.dot(x.T, R), x) + lmda\n",
    "        \n",
    "        # 3. error\n",
    "        def Error(x, y, w, lmda):\n",
    "            t = self.Sigmoid(np.dot(self.x, w))\n",
    "            return np.dot(np.dot(w.T, lmda/2), w) - np.sum(y*np.log(t) + (1 - y*np.log(t)))\n",
    "        \n",
    "        print(\"Initial error:\", Error(self.x, self.y, w, self.reg_vec))\n",
    "        # 4. 運算：只要error進步的值仍大於tol，就執行迴圈，滿足error 小於tol後，儲存w：\n",
    "        for i in range(self.max_iter):\n",
    "            error_old = Error(self.x, self.y, w, self.reg_vec)  # 初始w的error值\n",
    "            w -= np.dot(np.linalg.inv(Hessian(self.x, w, self.reg_vec)), Gradient(self.x, self.y, w, self.reg_vec))\n",
    "            error_new = Error(self.x, self.y, w, self.reg_vec)\n",
    "            print(\"iter round\", i+1, \"error:\", error_new)\n",
    "\n",
    "            if abs(error_new) < abs(error_old):  # 保留可產生error最小的w\n",
    "                optimal_w = w\n",
    "                \n",
    "            if abs(error_new - error_old) < self.tol:  # error進步幅度過小就停止\n",
    "                break\n",
    "\n",
    "        self.w = optimal_w\n",
    "        return self.w\n",
    "\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        if self.add_intercept == True:  # 處理intercept\n",
    "            self.x_test = np.hstack((x_test, np.ones((x_test.shape[0], 1))))\n",
    "            \n",
    "        # 1. 計算P(Y|X)，再做二元分類(機率介於0~1，直接四捨五入)，寫成一個array\n",
    "        t = self.Sigmoid(np.dot(self.x_test, self.w))\n",
    "        t = t.round()        \n",
    "        # 2. 回傳該二元分類array\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 1: lambda = 1 for all coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:07:04.328104Z",
     "start_time": "2020-05-01T13:07:04.324844Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_vec1 = np.diag(np.ones(x_train.shape[1] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:07:55.246600Z",
     "start_time": "2020-05-01T13:07:04.942043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: -30151.184662909913\n",
      "iter round 1 error: -30143.669924741942\n",
      "iter round 2 error: -30131.20997897284\n",
      "iter round 3 error: -30118.808974215895\n",
      "iter round 4 error: -30111.09925965939\n",
      "iter round 5 error: -30109.103391153676\n",
      "iter round 6 error: -30108.96163443724\n",
      "iter round 7 error: -30108.960420891963\n",
      "iter round 8 error: -30108.960420739604\n"
     ]
    }
   ],
   "source": [
    "logic = mylogistic_l2(reg_vec = lambda_vec1, max_iter = 30, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train) \n",
    "y_pred = logic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:08:01.910824Z",
     "start_time": "2020-05-01T13:08:01.892319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848688143473929"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 2: lambda = 1 for all but the intercept, no regularization for intercept term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:09:56.128957Z",
     "start_time": "2020-05-01T13:09:56.124761Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_vec2 = np.diag(np.hstack((np.ones(x_train.shape[1]), 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:10:43.128306Z",
     "start_time": "2020-05-01T13:09:58.245402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: -30151.19495088686\n",
      "iter round 1 error: -30148.29712786545\n",
      "iter round 2 error: -30144.06509453287\n",
      "iter round 3 error: -30139.807153521666\n",
      "iter round 4 error: -30136.170487142077\n",
      "iter round 5 error: -30134.958982917244\n",
      "iter round 6 error: -30134.862397269226\n",
      "iter round 7 error: -30134.861454746464\n",
      "iter round 8 error: -30134.861454592\n"
     ]
    }
   ],
   "source": [
    "logic = mylogistic_l2(reg_vec = lambda_vec2, max_iter = 30, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train) \n",
    "y_pred = logic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:10:54.643464Z",
     "start_time": "2020-05-01T13:10:54.635551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848090335436732"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:08:22.340269Z",
     "start_time": "2020-05-01T13:08:22.332631Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_vec3 = np.diag(np.hstack((np.ones(5), np.array([0.5] * 89), 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:09:16.311446Z",
     "start_time": "2020-05-01T13:08:31.260231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: -30151.591304092657\n",
      "iter round 1 error: -30149.912681528716\n",
      "iter round 2 error: -30147.332186583728\n",
      "iter round 3 error: -30144.626070038288\n",
      "iter round 4 error: -30141.867480138906\n",
      "iter round 5 error: -30140.496065036386\n",
      "iter round 6 error: -30140.362384652042\n",
      "iter round 7 error: -30140.360895329028\n",
      "iter round 8 error: -30140.360895055914\n"
     ]
    }
   ],
   "source": [
    "logic = mylogistic_l2(reg_vec = lambda_vec3, max_iter = 30, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train)\n",
    "y_pred = logic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:09:41.579097Z",
     "start_time": "2020-05-01T13:09:41.570792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478910660909996"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1.4 (10%) Further split the training data into subtraining (90%) and tuning (10%) to search for the best hyperparameters. Set the regularization coefficient for the constant term to zero. Allow different regularizations for continuous-valued and binary-valued features. Let 𝑎1 and 𝑎2 denote the regularization coefficients for continuous-valued and binary-valued features. Search the best 𝑎1 and 𝑎2 and report the test accuracy using the best hyper-parameters. You should follow the following procedure to search for the best hyperparameters.\n",
    "    1. Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100].\n",
    "    2. Conduct grid search with the constraint that 𝑎1 = 𝑎2. Record the best value 𝑎∗1 and 𝑎∗2.\n",
    "    3. Fix 𝑎1=𝑎∗1, and search 𝑎2 for the best value, call the result the new 𝑎∗2.\n",
    "    4. Fix  𝑎2=𝑎∗2, and search 𝑎1 for the best value.\n",
    "    5. Report the selected 𝑎1 and 𝑎2.\n",
    "    6. Train a model using the selected hyper-parameters, and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T12:30:14.374604Z",
     "start_time": "2020-05-01T12:30:14.237907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_subtrain, x_tune, y_subtrain, y_tune = train_test_split(x_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:16:38.162730Z",
     "start_time": "2020-05-01T13:16:38.157867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97817706, 0.05070542, 0.54873444, 0.23872403, 0.75053172])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grids\n",
    "gridset = np.random.rand(5)  # 因為hessian的運算速度較慢，因此取5grids\n",
    "gridset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fix 𝑎1=𝑎∗1, and search 𝑎2 for the best value, call the result the new 𝑎∗2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:30:27.974259Z",
     "start_time": "2020-05-01T13:27:13.699508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = a2 = 0.9781770599951939\n",
      "Initial error: -27135.470098497797\n",
      "iter round 1 error: -27132.39206568755\n",
      "iter round 2 error: -27128.29065182022\n",
      "iter round 3 error: -27124.028901440146\n",
      "iter round 4 error: -27120.48566369065\n",
      "iter round 5 error: -27119.414976716496\n",
      "iter round 6 error: -27119.335431286872\n",
      "iter round 7 error: -27119.33474043618\n",
      "iter round 8 error: -27119.334740348044\n",
      "a1 = a2 = 0.050705422604084505\n",
      "Initial error: -27135.971846561595\n",
      "iter round 1 error: -27135.68198901164\n",
      "iter round 2 error: -27135.184593444756\n",
      "iter round 3 error: -27134.550778176093\n",
      "iter round 4 error: -27133.603266667622\n",
      "iter round 5 error: -27131.647690284623\n",
      "iter round 6 error: -27132.79463701689\n",
      "iter round 7 error: -27132.273933070974\n",
      "iter round 8 error: -27132.32981681185\n",
      "iter round 9 error: -27132.328637509345\n",
      "iter round 10 error: -27132.328637034712\n",
      "a1 = a2 = 0.5487344441134364\n",
      "Initial error: -27135.69937151129\n",
      "iter round 1 error: -27133.802446883376\n",
      "iter round 2 error: -27131.09031719439\n",
      "iter round 3 error: -27128.14025219431\n",
      "iter round 4 error: -27125.209060527595\n",
      "iter round 5 error: -27124.02890732517\n",
      "iter round 6 error: -27123.93280617739\n",
      "iter round 7 error: -27123.931923831777\n",
      "iter round 8 error: -27123.93192372398\n",
      "a1 = a2 = 0.23872403214553295\n",
      "Initial error: -27135.868125023335\n",
      "iter round 1 error: -27134.924764231855\n",
      "iter round 2 error: -27133.48057888965\n",
      "iter round 3 error: -27131.795921187822\n",
      "iter round 4 error: -27129.700310914446\n",
      "iter round 5 error: -27127.926522875234\n",
      "iter round 6 error: -27127.795346141396\n",
      "iter round 7 error: -27127.791620664695\n",
      "iter round 8 error: -27127.791616330946\n",
      "a1 = a2 = 0.7505317229016107\n",
      "Initial error: -27135.590997914027\n",
      "iter round 1 error: -27133.12022714706\n",
      "iter round 2 error: -27129.71368389579\n",
      "iter round 3 error: -27126.09985420041\n",
      "iter round 4 error: -27122.83884765273\n",
      "iter round 5 error: -27121.742664145022\n",
      "iter round 6 error: -27121.6594209568\n",
      "iter round 7 error: -27121.65871287642\n",
      "iter round 8 error: -27121.658712787506\n",
      "Optimal lambda for continuous-valued = 0.23872403214553295\n",
      "Optimal lambda for binary-valued = 0.23872403214553295\n"
     ]
    }
   ],
   "source": [
    "optimal_a1 = None\n",
    "optimal_a2 = None\n",
    "optimal_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([i]*5 + [i]*89 + [0]), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a1 = a2 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    y_pred = logic.predict(x_tune)\n",
    "    if accuracy_score(y_pred, y_tune) > optimal_accuracy:\n",
    "        optimal_accuracy = accuracy_score(y_pred, y_tune)\n",
    "        optimal_a1 = i\n",
    "        optimal_a2 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", optimal_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", optimal_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fix 𝑎1=𝑎∗1, and search 𝑎2 for the best value, call the result the new 𝑎∗2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:42:28.917553Z",
     "start_time": "2020-05-01T13:39:20.395326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.9781770599951939\n",
      "Initial error: -27135.46984079232\n",
      "iter round 1 error: -27132.397962076895\n",
      "iter round 2 error: -27128.30489495188\n",
      "iter round 3 error: -27124.052371295063\n",
      "iter round 4 error: -27120.51333235492\n",
      "iter round 5 error: -27119.443249255728\n",
      "iter round 6 error: -27119.36372388253\n",
      "iter round 7 error: -27119.363033065518\n",
      "iter round 8 error: -27119.36303297738\n",
      "a2 = 0.050705422604084505\n",
      "Initial error: -27135.97178193153\n",
      "iter round 1 error: -27135.680511470444\n",
      "iter round 2 error: -27135.181047621998\n",
      "iter round 3 error: -27134.544738285327\n",
      "iter round 4 error: -27133.594710412217\n",
      "iter round 5 error: -27131.634095705056\n",
      "iter round 6 error: -27132.785802338745\n",
      "iter round 7 error: -27132.26165589399\n",
      "iter round 8 error: -27132.318914933643\n",
      "iter round 9 error: -27132.317681347464\n",
      "iter round 10 error: -27132.317680831347\n",
      "a2 = 0.5487344441134364\n",
      "Initial error: -27135.699359025057\n",
      "iter round 1 error: -27133.804911145082\n",
      "iter round 2 error: -27131.096249458315\n",
      "iter round 3 error: -27128.150145197193\n",
      "iter round 4 error: -27125.22080861747\n",
      "iter round 5 error: -27124.040770778196\n",
      "iter round 6 error: -27123.944677202675\n",
      "iter round 7 error: -27123.94379486482\n",
      "iter round 8 error: -27123.943794757022\n",
      "a2 = 0.23872403214553295\n",
      "Initial error: -27135.868125023335\n",
      "iter round 1 error: -27134.924764231855\n",
      "iter round 2 error: -27133.48057888965\n",
      "iter round 3 error: -27131.795921187822\n",
      "iter round 4 error: -27129.700310914446\n",
      "iter round 5 error: -27127.926522875234\n",
      "iter round 6 error: -27127.795346141396\n",
      "iter round 7 error: -27127.791620664695\n",
      "iter round 8 error: -27127.791616330946\n",
      "a2 = 0.7505317229016107\n",
      "Initial error: -27135.590901866854\n",
      "iter round 1 error: -27133.12430155987\n",
      "iter round 2 error: -27129.72350868329\n",
      "iter round 3 error: -27126.11613750006\n",
      "iter round 4 error: -27122.858076650053\n",
      "iter round 5 error: -27121.762238062216\n",
      "iter round 6 error: -27121.67900800022\n",
      "iter round 7 error: -27121.678299942345\n",
      "iter round 8 error: -27121.678299853433\n",
      "Optimal lambda for continuous-valued = 0.23872403214553295\n",
      "Optimal lambda for binary-valued = 0.23872403214553295\n"
     ]
    }
   ],
   "source": [
    "optimal_a2 = None\n",
    "optimal_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([optimal_a1]*5 + [i]*89 + [0]), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a2 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    y_pred = logic.predict(x_tune)\n",
    "    if accuracy_score(y_pred, y_tune) > optimal_accuracy:\n",
    "        optimal_accuracy = accuracy_score(y_pred, y_tune)\n",
    "        optimal_a2 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", optimal_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", optimal_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fix  𝑎2=𝑎∗2, and search 𝑎1 for the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:45:58.724041Z",
     "start_time": "2020-05-01T13:42:45.964277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.9781770599951939\n",
      "Initial error: -27135.867980435578\n",
      "iter round 1 error: -27134.9189439075\n",
      "iter round 2 error: -27133.466608461826\n",
      "iter round 3 error: -27131.772355395373\n",
      "iter round 4 error: -27129.671145508863\n",
      "iter round 5 error: -27127.897704165036\n",
      "iter round 6 error: -27127.765496034113\n",
      "iter round 7 error: -27127.761768189546\n",
      "iter round 8 error: -27127.761763857263\n",
      "a1 = 0.050705422604084505\n",
      "Initial error: -27135.868161728347\n",
      "iter round 1 error: -27134.926257336865\n",
      "iter round 2 error: -27133.484163388293\n",
      "iter round 3 error: -27131.801969358345\n",
      "iter round 4 error: -27129.707799305936\n",
      "iter round 5 error: -27127.93392596735\n",
      "iter round 6 error: -27127.8030145006\n",
      "iter round 7 error: -27127.79928967119\n",
      "iter round 8 error: -27127.799285337067\n",
      "a1 = 0.5487344441134364\n",
      "Initial error: -27135.868064450875\n",
      "iter round 1 error: -27134.922314082556\n",
      "iter round 2 error: -27133.474697365564\n",
      "iter round 3 error: -27131.78599873551\n",
      "iter round 4 error: -27129.688028401906\n",
      "iter round 5 error: -27127.91438356257\n",
      "iter round 6 error: -27127.782772129845\n",
      "iter round 7 error: -27127.77904562642\n",
      "iter round 8 error: -27127.779041293288\n",
      "a1 = 0.23872403214553295\n",
      "Initial error: -27135.868125023335\n",
      "iter round 1 error: -27134.924764231855\n",
      "iter round 2 error: -27133.48057888965\n",
      "iter round 3 error: -27131.795921187822\n",
      "iter round 4 error: -27129.700310914446\n",
      "iter round 5 error: -27127.926522875234\n",
      "iter round 6 error: -27127.795346141396\n",
      "iter round 7 error: -27127.791620664695\n",
      "iter round 8 error: -27127.791616330946\n",
      "a1 = 0.7505317229016107\n",
      "Initial error: -27135.86802498715\n",
      "iter round 1 error: -27134.920726979675\n",
      "iter round 2 error: -27133.470887929427\n",
      "iter round 3 error: -27131.779573015676\n",
      "iter round 4 error: -27129.68007612612\n",
      "iter round 5 error: -27127.906526178795\n",
      "iter round 6 error: -27127.77463356687\n",
      "iter round 7 error: -27127.77090642168\n",
      "iter round 8 error: -27127.77090208895\n",
      "Optimal lambda for continuous-valued = 0.9781770599951939\n",
      "Optimal lambda for binary-valued = 0.23872403214553295\n"
     ]
    }
   ],
   "source": [
    "optimal_a1 = None\n",
    "optimal_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([i]*5 + [optimal_a2]*89 + [0]), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a1 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    y_pred = logic.predict(x_tune)\n",
    "    if accuracy_score(y_pred, y_tune) > optimal_accuracy:\n",
    "        optimal_accuracy = accuracy_score(y_pred, y_tune)\n",
    "        optimal_a1 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", optimal_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", optimal_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如上所示，我選擇模型lambda參數為連續型變數0.978、二元變數0.238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model using the selected hyper-parameters, and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:00:31.346490Z",
     "start_time": "2020-05-01T13:59:35.430706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error: -30151.793257464287\n",
      "iter round 1 error: -30147.427157154445\n",
      "iter round 2 error: -30139.433150392284\n",
      "iter round 3 error: -30130.76570718343\n",
      "iter round 4 error: -30124.778304556654\n",
      "iter round 5 error: -30122.310200312695\n",
      "iter round 6 error: -30121.954901470195\n",
      "iter round 7 error: -30121.947646305416\n",
      "iter round 8 error: -30121.947636911125\n",
      "Accuracy score with hyper parameter: 0.8477582198605115\n"
     ]
    }
   ],
   "source": [
    "logic = mylogistic_l2(reg_vec = np.diag([i]*5 + [optimal_a2]*89 + [optimal_a1]), max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train)\n",
    "y_pred = logic.predict(x_test)\n",
    "print(\"Accuracy score with hyper parameter:\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:02:36.222617Z",
     "start_time": "2020-05-01T14:02:36.176462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6037327562888829 recall: 0.7296502124877411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10531,  1465],\n",
       "       [  827,  2232]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "print(\"Precision:\", precision_score(y_pred, y_test), \"recall:\", recall_score(y_pred, y_test))\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1.5 (20%) Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning). Compare the estimated parameters and test accuracy with those from your own models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:11:49.934527Z",
     "start_time": "2020-05-01T14:11:49.609066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(penalty = \"l2\", tol = 1e-5, max_iter = 1000, fit_intercept = True )\n",
    "LR.fit(x_train, y_train)\n",
    "y_pred = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:11:51.548318Z",
     "start_time": "2020-05-01T14:11:51.539542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843639986715377"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:11:53.453716Z",
     "start_time": "2020-05-01T14:11:53.424417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5777657560183933 recall: 0.7292591328098327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10565,  1561],\n",
       "       [  793,  2136]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Precision:\", precision_score(y_pred, y_test), \"recall:\", recall_score(y_pred, y_test))\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sklearn的logistic regression，可以得到準確率約為0.8436，相比自己設計、經過tuning後的模型低了約0.5%，另外看precision rate與recall rate也都較scikit-learn的模型要高出一些，顯示出parameter tuning的重要性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
